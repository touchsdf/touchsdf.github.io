<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <!-- <meta name="keywords" content="Nerfies, D-NeRF, NeRF"> -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>TouchSDF</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <!-- <link rel="icon" href="./static/images/camera.png"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <!-- Render objects -->
  <!-- Import the component -->
  <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>

  <!-- Custom CSS -->
  <link rel="stylesheet" href="./static/css/custom.css">
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->

<section class="hero">
  <div class="hero-body" style="padding-bottom: 0rem";>
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">TouchSDF: A DeepSDF Approach for 3D Shape Reconstruction Using Vision-Based Tactile Sensing</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <span style="color:hsl(204, 86%, 53%)">Mauro Comi</span><sup>1</sup></span>,
              <span style="color:hsl(204, 86%, 53%)">Yijiong Lin</span><sup>1,2</sup></span>,
              <span style="color:hsl(204, 86%, 53%)">Alex Church</span><sup>1</sup></span>,
              <span style="color:hsl(204, 86%, 53%)">Alessio Tonioni</span><sup>3</sup></span>,
              <span style="color:hsl(204, 86%, 53%)">Laurence Aitchison</span><sup>1</sup></span>,
              <span style="color:hsl(204, 86%, 53%)">Nathan Lepora</span><sup>1,2</sup></span>,
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Bristol</span>,
            <span class="author-block"><sup>2</sup>Bristol Robotics Laboratory</span>,
            <span class="author-block"><sup>3</sup>Google ZÃ¼rich</span>

          </div>

          <div class="column has-text-centered">
            <div class="publication-links">

              <!-- Paper Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2311.12602"
                   class="external-link button is-normal is-rounded btn-grad">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>ArXiv Paper</span>
                </a>
              </span>

              <!-- PDF Link. -->
              <span class="link-block">
                <a href="documents/supplementary.pdf"
                   class="external-link button is-normal is-rounded btn-grad">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Supplementary</span>
                </a>
              </span>

              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded btn-grad">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->

              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->

              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/maurock/TouchSDF"
                   class="external-link button is-normal is-rounded btn-grad">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
                </span> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->



<section class="section">
  

  <div class="container is-max-desktop">
    
    <div class="content" style="text-align: center; align-items: center; justify-content: center; font-size: 20px; margin-bottom: 40px;">
      TouchSDF helps robots understand and reconstruct 3D shapes using their sense of touch, both in simulations and in the real world.
    </div>

    <div class="columns is-centered">
      <img src="./static/images/architecture_3.jpg" alt="Image"> 
    </div>

    <div class="content has-text-justified">
      Overview of TouchSDF: (1) A robot samples the object's surface to obtain real tactile images (marker patterns) that are translated into simulated images (depth maps). (2) A Convolutional Neural Network (CNN) maps the simulated images to sets of 3D points representing the local object surface at the touch locations. (3) A pre-trained DeepSDF model predicts a continuous signed-distance function (SDF) representing the object shape from the point clouds over multiple contacts.
    </div>

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">

  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          Humans rely on their visual and tactile senses to develop a comprehensive 3D understanding of their physical environment. Recently, there has been a growing interest in exploring and manipulating objects using data-driven approaches that utilise high-resolution vision-based tactile sensors. However, 3D shape reconstruction using tactile sensing has lagged behind visual shape reconstruction because of limitations in existing techniques, including the inability to generalise over unseen shapes, absence of real-world testing and limited expressive capacity imposed by discrete representations. To address these challenges, we propose <b>TouchSDF</b>, a Deep Learning approach for tactile 3D shape reconstruction that leverages the rich information provided by a vision-based tactile sensor and the expressivity of the implicit neural representation DeepSDF. This combination allows TouchSDF to reconstruct smooth and continuous 3D shapes from tactile inputs in simulation and real-world settings, opening up research avenues for robust 3D-aware representations and improved multimodal perception for robot manipulation.
        </div>
      </div>
      
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">

      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          Coming soon...

        </div>
      </div>
    </div> -->


  </div>
</section>

<section class="section">

  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Tactile data to contact geometry</h2>
    </div>

    <div class="columns is-centered" style="margin-top: 20px; ">
      <img src="./static/images/data_collection_tactile_pointcloud.png" alt="Image" style="width: 80%;" > 
    </div>

  </div>

</section>


<section class="section">

  <div class="container is-max-desktop">

  <div class="columns is-centered has-text-centered" style="margin-top: 40px; ">
    <h2 class="title is-3">Comparison with prior work</h2>
  </div>

  We compared our method to <a href="https://arxiv.org/abs/2107.09584">Smith et al.</a>'s' touch-only reconstruction approach, using the Earth Mover's Distance (EMD), Camfer Distance (CD), and Surface Reconstruction Error as metrics. TouchSDF achieves better EMD and Surface Reconstruction Error, while achieving slightly lower CD despite a better visual quality. 

  <div class="columns is-centered" style="margin-top: 20px; ">
    <img src="./static/images/comparison_smith_new.jpg" alt="Image" style="width: 90%;" > 
  </div>
  </div>
</section>


</div>

</section>

<section class="section">

  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Reconstructions: Simulation</h2>
    </div>

    <div class="columns is-centered has-text-centered" style="margin-top: 20px;">
      <p>You can interact with the ground truth and reconstructed meshes below to assess the quality of our 3D shape reconstruction approach.</p>
    </div>
  
    <!-- Camera -->
    <div class="columns is-centered has-text-centered">
      <div class="model-viewer-container">
        <div class="overlay">Ground truth</div>
        <model-viewer id="camera_gt" src="documents/meshes/camera_gt.glb" camera-controls shadow-intensity="1.4" exposure="0.9 shadow-softness="1" auto-rotate rotation-per-second="40deg">
        </model-viewer>
      </div>
      <div class="model-viewer-container">
        <div class="overlay">Reconstruction</div>
        <model-viewer id="camera_rec" src="documents/meshes/camera_rec.glb" camera-controls shadow-intensity="1.4" exposure="0.9  shadow-softness="1" auto-rotate rotation-per-second="40deg">
        </model-viewer>
      </div>
    </div>
    
    <!-- Bottle -->
    <div class="columns is-centered has-text-centered">
      <model-viewer id="bottle_rec" src="documents/meshes/bottle_gt.glb" camera-controls shadow-intensity="1.4" exposure="0.9" shadow-softness="1" auto-rotate rotation-per-second="40deg">
      </model-viewer>
      <model-viewer id="bottle_gt" src="documents/meshes/bottle_rec.glb" camera-controls shadow-intensity="1.4" exposure="0.9" shadow-softness="1" auto-rotate rotation-per-second="40deg">
      </model-viewer>
    </div>

    <!-- Mug -->
    <div class="columns is-centered has-text-centered">
        <model-viewer id="mug_gt" src="documents/meshes/mug_gt.glb" camera-controls shadow-intensity="1.4" exposure="0.9" shadow-softness="1" auto-rotate rotation-per-second="40deg">
        </model-viewer>
        <model-viewer id="mug_rec" src="documents/meshes/mug_rec.glb" camera-controls shadow-intensity="1.4" exposure="0.9" shadow-softness="1" auto-rotate rotation-per-second="40deg">
        </model-viewer>
    </div>

    <!-- Guitar -->
    <div class="columns is-centered has-text-centered">
      <model-viewer id="guitar_gt" src="documents/meshes/guitar_gt.glb" camera-controls shadow-intensity="1.1" exposure="0.9shadow-softness="1" auto-rotate rotation-per-second="40deg">
      </model-viewer>
      <model-viewer id="guitar_rec" src="documents/meshes/guitar_rec.glb" camera-controls shadow-intensity="1.1" exposure="0.9" shadow-softness="1" auto-rotate rotation-per-second="40deg">
      </model-viewer>
    </div>

    <script>
      const elementIds = ['camera_gt', 'camera_rec', 'bottle_gt', 'bottle_rec', 'guitar_gt', 'guitar_rec', 'mug_gt', 'mug_rec'];
      elementIds.forEach(elementId => {
        const modelViewerColor = document.querySelector(`model-viewer#${elementId}`);
        if (modelViewerColor) {
          modelViewerColor.addEventListener('load', () => {
          const [material] = modelViewerColor.model.materials;
          material.pbrMetallicRoughness.setBaseColorFactor("#fd8c3e");
          });
        }
      });
    </script>

  </div>

</section>



<section class="section">

  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Reconstructions: Real world</h2>
    </div>

    Our method successfully reconstructed real 3D-printed objects and additional everyday objects (a mug and a transparent jar), achieving low EMD values that are comparable to those obtained in simulation.

    <div class="columns is-centered" style="margin-top: 20px; ">
      <img src="./static/images/reconstruction_real.jpg" alt="Image" style="width: 80%;" > 
    </div>

  </div>

</section>



<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>